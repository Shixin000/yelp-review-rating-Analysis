{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NBclassifier.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN0aY2AffZyII0iXwRupcqV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZiHwRVnPlKzv","colab_type":"text"},"source":["Assume data cleaning works(preprocessing) is finished.\n","## **Task:**\n","\n","1. built the training function\n","   * Accepts word2vec matrix and the rating corresponding to each row of matrix\n","2. bulid n-grams feature function\n","  * use nltk.ngrams(test_sentence,n)\n","3. then make a dictionary with n-grams\n","4. Word2vec \n","5. built the classifier\n","6. Train the data set \n","7. Calculate the accuracy"]},{"cell_type":"code","metadata":{"id":"3EJpvakW9rQ_","colab_type":"code","outputId":"38a1d6a1-e166-4849-c566-63e2b3757745","executionInfo":{"status":"ok","timestamp":1590633744281,"user_tz":420,"elapsed":22511,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XMzLZPu4lO1C","colab_type":"code","outputId":"8a25085f-23b4-4b07-e65e-e630d3c680a9","executionInfo":{"status":"ok","timestamp":1590633750934,"user_tz":420,"elapsed":3641,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import nltk\n","from nltk import ngrams\n","from nltk import word_tokenize\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","import numpy as np\n","import pprint\n","import re\n","\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LE8dj8Cc8BDm","colab_type":"code","outputId":"78753eb0-2f6e-4d59-a911-d8815f666fd3","executionInfo":{"status":"ok","timestamp":1590633760716,"user_tz":420,"elapsed":7308,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["nltk.download('popular')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading collection 'popular'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet.zip.\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection popular\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"36pMqQxR9naf","colab_type":"text"},"source":["#Load the data"]},{"cell_type":"code","metadata":{"id":"vEPhKuujsW2J","colab_type":"code","outputId":"0267787b-0d3a-4066-9ed4-d201ca69eced","executionInfo":{"status":"ok","timestamp":1590633773590,"user_tz":420,"elapsed":4459,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["path = '/content/drive/My Drive/cs182proj/NLP data set/preprocessed_remove_stopwords_stem.csv'\n","reviews = pd.read_csv(path)\n","reviews.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stars</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>total bill horribl servic over gs crook actual...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>ador travi hard rock new kelli cardena salon a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.0</td>\n","      <td>say offic realli togeth organ friendli dr j ph...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.0</td>\n","      <td>went lunch steak sandwich delici caesar salad ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>today second out three session paid although f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   stars                                             review\n","0    1.0  total bill horribl servic over gs crook actual...\n","1    5.0  ador travi hard rock new kelli cardena salon a...\n","2    5.0  say offic realli togeth organ friendli dr j ph...\n","3    5.0  went lunch steak sandwich delici caesar salad ...\n","4    1.0  today second out three session paid although f..."]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"HnQi9scx-U1c","colab_type":"code","outputId":"75dcc677-4249-4742-ba46-945012b3b939","executionInfo":{"status":"ok","timestamp":1590633775717,"user_tz":420,"elapsed":606,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(reviews)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["533581"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"dlRh6CuF-NlW","colab_type":"text"},"source":["#Tokenize the text and remove Non-english text"]},{"cell_type":"code","metadata":{"id":"fGFJdTff-NFk","colab_type":"code","colab":{}},"source":["reviews['review_tokenize'] = reviews['review'].apply(lambda r: word_tokenize(r) if(type(r)!=float) else 'NA')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pA1FTIwugvL","colab_type":"code","colab":{}},"source":["reviews = reviews.iloc[list(reviews['review_tokenize'].apply(lambda r: r[0] != 'NA' and r[0] != 'unklang'))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZTRhXvAjxC0","colab_type":"code","outputId":"288d05c0-5b7a-4013-aca4-d9cae6ea53f0","executionInfo":{"status":"ok","timestamp":1590633935671,"user_tz":420,"elapsed":486,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["reviews.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stars</th>\n","      <th>review</th>\n","      <th>review_tokenize</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>total bill horribl servic over gs crook actual...</td>\n","      <td>[total, bill, horribl, servic, over, gs, crook...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>ador travi hard rock new kelli cardena salon a...</td>\n","      <td>[ador, travi, hard, rock, new, kelli, cardena,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.0</td>\n","      <td>say offic realli togeth organ friendli dr j ph...</td>\n","      <td>[say, offic, realli, togeth, organ, friendli, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.0</td>\n","      <td>went lunch steak sandwich delici caesar salad ...</td>\n","      <td>[went, lunch, steak, sandwich, delici, caesar,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>today second out three session paid although f...</td>\n","      <td>[today, second, out, three, session, paid, alt...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   stars  ...                                    review_tokenize\n","0    1.0  ...  [total, bill, horribl, servic, over, gs, crook...\n","1    5.0  ...  [ador, travi, hard, rock, new, kelli, cardena,...\n","2    5.0  ...  [say, offic, realli, togeth, organ, friendli, ...\n","3    5.0  ...  [went, lunch, steak, sandwich, delici, caesar,...\n","4    1.0  ...  [today, second, out, three, session, paid, alt...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"NnRQQ4bM71kX","colab_type":"code","outputId":"1725b8dc-ee69-478e-e3fc-3f77e57036c9","executionInfo":{"status":"ok","timestamp":1590633939668,"user_tz":420,"elapsed":641,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(reviews)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["529707"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"YdtylQUZOjXC","colab_type":"text"},"source":["#Remove the low frequncy words"]},{"cell_type":"code","metadata":{"id":"ZB5YHKp1OidG","colab_type":"code","colab":{}},"source":["words_collection = []\n","review_tokenize = reviews['review_tokenize']\n","for i in review_tokenize:\n","  words_collection.extend(i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sU3swt6rSDtQ","colab_type":"code","outputId":"0f5ffaf9-5662-40a8-c415-2afb8af78f0d","executionInfo":{"status":"ok","timestamp":1590633950203,"user_tz":420,"elapsed":968,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(words_collection)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28558674"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"MWBlW1RxSwNy","colab_type":"code","colab":{}},"source":["words_collection = pd.Series(words_collection)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZbfGOqZe2mj","colab_type":"code","colab":{}},"source":["words_count = words_collection.value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdonIKwcIurf","colab_type":"code","outputId":"f8a32e08-1f69-454d-8cce-021e097e6e8e","executionInfo":{"status":"ok","timestamp":1590633960754,"user_tz":420,"elapsed":1117,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(words_count)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["235598"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"FlX9qWbqI0xs","colab_type":"code","outputId":"82ac1706-ddef-4e26-feff-f6bd1d8b18b8","executionInfo":{"status":"ok","timestamp":1590635130352,"user_tz":420,"elapsed":570,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["low_freq_words = words_count[words_count.values <= 15000]\n","len(low_freq_words)"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["235237"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"DxhHYyYfJ29w","colab_type":"code","outputId":"5bc887c5-56b6-42d7-97a6-d384cfcf7e3f","executionInfo":{"status":"ok","timestamp":1590635133358,"user_tz":420,"elapsed":662,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sini_words = words_count[words_count.values > 15000]\n","len(sini_words)"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["361"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"1A9tjq1ELCoy","colab_type":"code","colab":{}},"source":["reviews['sinificant words'] = reviews['review_tokenize'].apply(lambda r: [i for i in r if i in sini_words and len(i)>1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-1sEIMFPTAp","colab_type":"text"},"source":["##***Input of function train_NB_ngrams***"]},{"cell_type":"code","metadata":{"id":"mlqZlqx59Wef","colab_type":"code","outputId":"06ae999f-bf9d-4b8b-c64c-f55dd43aeeff","executionInfo":{"status":"ok","timestamp":1590635173402,"user_tz":420,"elapsed":632,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["reviews.head(10)"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stars</th>\n","      <th>review</th>\n","      <th>review_tokenize</th>\n","      <th>sinificant words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>total bill horribl servic over gs crook actual...</td>\n","      <td>[total, bill, horribl, servic, over, gs, crook...</td>\n","      <td>[total, bill, horribl, servic, over, actual, c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>ador travi hard rock new kelli cardena salon a...</td>\n","      <td>[ador, travi, hard, rock, new, kelli, cardena,...</td>\n","      <td>[hard, new, salon, alway, great, no, offer, se...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.0</td>\n","      <td>say offic realli togeth organ friendli dr j ph...</td>\n","      <td>[say, offic, realli, togeth, organ, friendli, ...</td>\n","      <td>[say, offic, realli, friendli, dr, great, veri...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.0</td>\n","      <td>went lunch steak sandwich delici caesar salad ...</td>\n","      <td>[went, lunch, steak, sandwich, delici, caesar,...</td>\n","      <td>[went, lunch, sandwich, delici, salad, absolut...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>today second out three session paid although f...</td>\n","      <td>[today, second, out, three, session, paid, alt...</td>\n","      <td>[today, second, out, three, paid, first, went,...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4.0</td>\n","      <td>first admit not excit go la tavolta food snob ...</td>\n","      <td>[first, admit, not, excit, go, la, tavolta, fo...</td>\n","      <td>[first, not, go, food, friend, go, dinner, loo...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.0</td>\n","      <td>traci dessert big name hong kong one first mar...</td>\n","      <td>[traci, dessert, big, name, hong, kong, one, f...</td>\n","      <td>[big, name, one, first, place, mani, year, cam...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1.0</td>\n","      <td>place gone down hill clearli cut back staff fo...</td>\n","      <td>[place, gone, down, hill, clearli, cut, back, ...</td>\n","      <td>[place, down, cut, back, staff, food, qualiti,...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2.0</td>\n","      <td>realli look forward visit beer man war quickli...</td>\n","      <td>[realli, look, forward, visit, beer, man, war,...</td>\n","      <td>[realli, look, visit, beer, favorit, good, swe...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3.0</td>\n","      <td>giant best buy regist not get big deal place</td>\n","      <td>[giant, best, buy, regist, not, get, big, deal...</td>\n","      <td>[best, buy, not, get, big, deal, place]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   stars  ...                                   sinificant words\n","0    1.0  ...  [total, bill, horribl, servic, over, actual, c...\n","1    5.0  ...  [hard, new, salon, alway, great, no, offer, se...\n","2    5.0  ...  [say, offic, realli, friendli, dr, great, veri...\n","3    5.0  ...  [went, lunch, sandwich, delici, salad, absolut...\n","4    1.0  ...  [today, second, out, three, paid, first, went,...\n","5    4.0  ...  [first, not, go, food, friend, go, dinner, loo...\n","6    3.0  ...  [big, name, one, first, place, mani, year, cam...\n","7    1.0  ...  [place, down, cut, back, staff, food, qualiti,...\n","8    2.0  ...  [realli, look, visit, beer, favorit, good, swe...\n","9    3.0  ...            [best, buy, not, get, big, deal, place]\n","\n","[10 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"LDWJpCnHPPTX","colab_type":"code","colab":{}},"source":["df = reviews[['stars','sinificant words']].sample(80000, replace=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pymXgezD9v_s","colab_type":"text"},"source":["#Training Function"]},{"cell_type":"code","metadata":{"id":"3jVAEqBFrVo-","colab_type":"code","colab":{}},"source":["# this clssifier works for different grams (n = 1,2,3...)\n","\n","def trainNB(sub_reviews_vector, review_cate):\n","    \"\"\"\n","    tsub_reviews_vector: a batch of the review text vectors, \n","                         with shape: (dictionary_len, batch_size)\n","    review_cate: a list(np.array) of the classes (rating) of the reviews, \n","                they look like [5.0, 1.0, 3.0, 4.0, 5.0, 2.0,.....]\n","    \"\"\"\n","    \"\"\"\n","    return: 1. a matrix in which each row represents the log of probabilities\n","            of features in the same class. \n","            2. a dictionary with the ratings as the keys, and the\n","            probabilities as their values\n","    \"\"\"\n","\n","    batch_size = len(sub_reviews_vector)\n","    reviews_vec_len = len(sub_reviews_vector[0])\n","    \n","    #initialize features distribution for all classes, and set all entries \n","    #equals to 1 (to avoid getting a 0 fraction), 5 represents the number of \n","    #different classes\n","    features_dist = np.ones((5,reviews_vec_len)) \n","\n","    #initialize the sum of features for all classes, and set all entries \n","    # equals to 1\n","    features_sum = np.ones(5)\n","    \n","    for i in range(len(sub_reviews_vector)):\n","      rating = review_cate[i]\n","      features_dist[int(rating)-1] += sub_reviews_vector[i]\n","      features_sum[int(rating)-1] += np.sum(sub_reviews_vector[i])\n","     \n","    #calcualte the log of probability of each features\n","    log_features_frac = np.ones((5,reviews_vec_len))\n","    for i in range(5):\n","      features_dist[i] /= features_sum[i]\n","      log_features_frac[i] = np.log(features_dist[i])\n","\n","    #calculate the fraction of each class in the review category list\n","    class_proba = class_prob(review_cate)\n","\n","    return [log_features_frac,class_proba]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vU2cqhLnBvqs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0sqjZ9vTKt4l","colab_type":"text"},"source":["#calculate the probability of each class "]},{"cell_type":"code","metadata":{"id":"Le2vY354HaDG","colab_type":"code","colab":{}},"source":["\n","def class_prob(review_cate):\n","    \"\"\"\n","    review_cate: a list(np.array) of the class type of the reviews, \n","                they look like [5.0, 1.0, 3.0, 4.0, 5.0, 2.0,.....]\n","    \"\"\"  \n","\n","    \"\"\"\n","    return: a dictionary with the rating as the keys and the corresponding\n","            probability in the set review_cate\n","    \"\"\"\n","\n","    review_cate = pd.Series(review_cate)\n","    val_count = review_cate.value_counts()\n","    class_proba = {}\n","    size = len(review_cate)\n","    \n","    for i in range(len(val_count)):\n","      class_proba[val_count.keys()[i]] = val_count.values[i]/size \n","\n","    return class_proba"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BTJJTvcTK6UJ","colab_type":"text"},"source":["#Create n-gram feature word of the reviews"]},{"cell_type":"code","metadata":{"id":"-Ui1NSb7Xy_x","colab_type":"code","colab":{}},"source":["def create_ngrams_text(reviews, n):\n","  \"\"\"\n","  reviews: a dataframe with the texts tokenize\n","  n: the number of grams\n","  \"\"\"\n","  \"\"\"\n","  return a list of reviews with n grams, and each n gram feature is \n","  a tuple\n","  \"\"\"\n","  ngrams_text = []\n","  for i in reviews:\n","    ngrams_review = ngrams(i,n)\n","    ngrams_review = [ng for ng in ngrams_review]\n","    ngrams_text.append(ngrams_review)\n","\n","  return ngrams_text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2i0XSWvj86ZW","colab_type":"text"},"source":["# Built a dictionary with n-gram word\n"]},{"cell_type":"code","metadata":{"id":"rVYGX1UM7ZBP","colab_type":"code","colab":{}},"source":["def create_ngram_dictionary(df, n):\n","  \"\"\"\n","  reviews: a data frame of reviews text with different classes(rating)\n","          in the second column\n","  n: the number of grams\n","  \"\"\"\n","  \"\"\"\n","  return a list of non-repeated n grams vocabulary \n","  \"\"\"\n","  reviews = df.iloc[:,1]\n","  dictionary = set()\n","  for i in reviews:\n","    ngrams_review = ngrams(i,n)\n","    ngram_review = set(ng for ng in ngrams_review)\n","    dictionary = dictionary.union(ngram_review)\n"," \n","  dictionary = list(dictionary)\n","\n","  return dictionary"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"crbmVFRfjovK","colab_type":"text"},"source":["#Word to vector"]},{"cell_type":"code","metadata":{"id":"xQ33b2kBjdiO","colab_type":"code","colab":{}},"source":["def setwords2vector(reviews, dictionary):\n","  \"\"\"\n","  rewiews: a list of reviews in n-grams fromate\n","  dictionary: the dictionary(a set of unique words) of reviews text in n-grams fromate\n","  \"\"\"\n","  \"\"\"\n","  return a words to vector matrix with shape(reviews_size, dictionary_len)\n","  \"\"\"\n","  num_row = len(reviews)\n","  num_column = len(dictionary)\n","  reviews2Matrix = np.zeros((len(reviews),len(dictionary)))\n","  for i in range(len(reviews)):\n","    for w in reviews[i]:\n","      if w in dictionary:\n","        reviews2Matrix[i][dictionary.index(w)] +=1\n","  return reviews2Matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"75iZMho55_SZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1MsIBhHmPvVG","colab_type":"text"},"source":["#Get the text of reviews and the corresponding ratings separately"]},{"cell_type":"code","metadata":{"id":"LE9P42ofPjrl","colab_type":"code","colab":{}},"source":["def get_reviews_rating(reviews):\n","  \"\"\"\n","  reviews: the dataframe\n","  \"\"\"\n","  \"\"\"\n","  return a list of text of reviews and ratings \n","  \"\"\"\n","  revs = np.array(reviews.iloc[:,1])\n","  ratings = np.array(reviews.iloc[:,0])\n","  return revs, ratings"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4dsP6wDba3p","colab_type":"text"},"source":["#Predict the rating"]},{"cell_type":"code","metadata":{"id":"OIFRGHqbblXv","colab_type":"code","colab":{}},"source":["def NBclassifier(classifier, word2vector):\n","    \"\"\"\n","    classifier: a list with element log_features_frac and class_proba\n","    log_features_frac: log value of the feature fraction with \n","                       shape(5,dictionary_len), and the first row is the frac\n","                       of class 1.0 ... the last row is class 5.0\n","    class_proba: a dictionary with the class(rating) as key and there fraction \n","                 in the data set as the value\n","    word2vector: a single vector representation of a review text with shape(1,dictionary_len)            \n","    \"\"\"\n","    \"\"\"\n","    return the predicted class(rating)\n","    \"\"\" \n","    log_features_frac, class_proba = classifier\n","    proba_class = {}\n","    for i in class_proba:\n","      class_classifier = log_features_frac[int(i)-1]\n","      proba = np.log(class_proba[i]) + sum(class_classifier*word2vector)\n","      proba_class[proba] = i\n","    class_ = proba_class[max(proba_class)]\n","    return class_"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rgba94OHp-BG","colab_type":"text"},"source":["#Calculate the accuracy"]},{"cell_type":"code","metadata":{"id":"0hLEZYAip9gs","colab_type":"code","colab":{}},"source":["def get_accuracy(pred_rating, actual_rating):\n","    \"\"\"\n","    pred_rating: a list of predicted rating\n","    actual_rating: a list of actual_rating with the same length as pred_rating\n","    \"\"\" \n","    \"\"\"\n","    return the accuracy of the prediction\n","    \"\"\" \n","    size = len(pred_rating)\n","    match = [pred_rating[i]==actual_rating[i] for i in range(size)]\n","    accuracy = sum(match)/size\n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OxYVqNhi6HKz","colab_type":"code","colab":{}},"source":["def get__accuracy(pred_rating, actual_rating):\n","    \"\"\"\n","    pred_rating: a list of predicted rating\n","    actual_rating: a list of actual_rating with the same length as pred_rating\n","    \"\"\" \n","    \"\"\"\n","    return the accuracy of the prediction\n","    \"\"\" \n","    size = len(pred_rating)\n","    match = []\n","    for i in range(size):\n","      a = pred_rating[i]>=4.0 and actual_rating[i]>=4.0\n","      b = pred_rating[i]==3.0 and actual_rating[i]==3.0\n","      c = pred_rating[i]<=2.0 and actual_rating[i]<=2.0\n","      boo = a or b or c\n","      match.append(boo)      \n","\n","    accuracy = sum(match)/size\n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Je2Y2RTIWQ5J","colab_type":"text"},"source":["#Get training and test set"]},{"cell_type":"code","metadata":{"id":"WEc8I5HoWPrw","colab_type":"code","colab":{}},"source":["def get_train_test_set(fraction, df):\n","  \"\"\"\n","  fraction: fraction of the test set\n","  df: data frame \n","  \"\"\"\n","  train, test = train_test_split(df, test_size=fraction)\n","  return train, test "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7aI4ZrizAUt","colab_type":"text"},"source":["#Train Naive Bayes Classifier for n grams"]},{"cell_type":"code","metadata":{"id":"O8zyhB3TuqjA","colab_type":"code","colab":{}},"source":["def train_NB_ngrams(df, n):\n","    \"\"\"\n","    dataSet: a dataframe with rating and the tokenized review text\n","    n: the number of grams\n","    \"\"\" \n","    \"\"\"\n","    return the accuracy of the n grams prediction \n","    \"\"\" \n","    #get training and test set\n","    training, test = get_train_test_set(0.2, df)\n","\n","    #get reviews and rating of training and test set separately \n","    tra_rev, tra_rating = get_reviews_rating(training)\n","    test_rev, test_rating = get_reviews_rating(test)\n","\n","    #get n-grams train and test vocabulary\n","    tra_rev_ngrams = create_ngrams_text(tra_rev, n)\n","    test_rev_ngrams = create_ngrams_text(test_rev, n)\n","\n","    #get n-grams dictionary\n","    dictionary = create_ngram_dictionary(df, n)\n","\n","    #train and test vocabulary to vector\n","    tra_words2vec = setwords2vector(tra_rev_ngrams, dictionary)\n","    test_words2vec = setwords2vector(test_rev_ngrams, dictionary)\n","\n","    #get classifier \n","    classifier = trainNB(tra_words2vec, tra_rating)\n","\n","    #predict rating\n","    preds = []\n","    for i in test_words2vec:\n","      prediction = NBclassifier(classifier, i)\n","      preds.append(prediction)\n","      \n","    #calculate the accuracy\n","    accu = get_accuracy(preds, test_rating)\n","\n","    return [accu, preds, test_rating]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUsr5CvXOn_Z","colab_type":"code","outputId":"4983ea54-b9e7-429e-f4c2-d8169dd09088","executionInfo":{"status":"ok","timestamp":1590635247641,"user_tz":420,"elapsed":36279,"user":{"displayName":"Shixin Li","photoUrl":"","userId":"11120222644890565746"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["accuracy, pred_rating, actual_rating= train_NB_ngrams(df, 1)\n","print(str(1)+'-gram accuracy: ', accuracy)\n","print(str(1)+'-gram actual rating distribution: ', class_prob(actual_rating))\n","print(str(1)+'-gram predicted rating distribution: ', class_prob(pred_rating))"],"execution_count":66,"outputs":[{"output_type":"stream","text":["1-gram accuracy:  0.654125\n","1-gram actual rating distribution:  {5.0: 0.4939375, 1.0: 0.241875, 4.0: 0.133875, 2.0: 0.068125, 3.0: 0.0621875}\n","1-gram predicted rating distribution:  {5.0: 0.45725, 1.0: 0.2468125, 4.0: 0.1866875, 3.0: 0.06275, 2.0: 0.0465}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZxKK2Je3Q5Vq","colab_type":"text"},"source":["#1-gram: \n","\n","**# sample: 20000**\n","\n","1-gram accuracy:  0.60575\n","\n","1-gram actual rating distribution:  {5.0: 0.48275, 1.0: 0.233, 4.0: 0.14675, 3.0: 0.06875, 2.0: 0.06875}\n","\n","1-gram predicted rating distribution: missing\n","\n","**# sample: 30000**\n","\n","(remove words appear less than 150)\n","\n","1-gram accuracy:  0.6206666666666667\n","\n","1-gram actual rating distribution:  {5.0: 0.482, 1.0: 0.24533333333333332, 4.0: 0.141, 2.0: 0.06966666666666667, 3.0: 0.062}\n","\n","1-gram predicted rating distribution:  {5.0: 0.3835, 1.0: 0.22633333333333333, 4.0: 0.20133333333333334, 3.0: 0.11116666666666666, 2.0: 0.07766666666666666}\n","\n","**# sample: 30000**\n","\n","ccuracy:  0.6371666666666667\n","\n","1-gram actual rating distribution:  {5.0: 0.505, 1.0: 0.23216666666666666, 4.0: 0.14266666666666666, 3.0: 0.06216666666666667, 2.0: 0.058}\n","\n","1-gram predicted rating distribution:  {5.0: 0.40166666666666667, 1.0: 0.225, 4.0: 0.21316666666666667, 3.0: 0.08616666666666667, 2.0: 0.074}\n","\n","**# sample: 30000**\n","\n","(remove words appear less than 300)\n","\n","1-gram accuracy:  0.6383333333333333\n","\n","1-gram actual rating distribution:  {5.0: 0.4835, 1.0: 0.24583333333333332, 4.0: 0.1375, 2.0: 0.0685, 3.0: 0.06466666666666666}\n","\n","1-gram predicted rating distribution:  {5.0: 0.38616666666666666, 1.0: 0.22583333333333333, 4.0: 0.20616666666666666, 3.0: 0.108, 2.0: 0.07383333333333333}\n","\n","**# sample: 40000**\n","\n","(remove words appear less than 500)\n","\n","1-gram accuracy:  0.643125\n","\n","1-gram actual rating distribution:  {5.0: 0.49175, 1.0: 0.246125, 4.0: 0.1335, 2.0: 0.065, 3.0: 0.063625}\n","\n","1-gram predicted rating distribution:  {5.0: 0.40075, 1.0: 0.23025, 4.0: 0.2105, 3.0: 0.09, 2.0: 0.0685}\n","\n","\n","**# sample: 40000**\n","\n","(remove words appear less than 900)\n","\n","1-gram accuracy:  0.64825\n","\n","1-gram actual rating distribution:  {5.0: 0.49525, 1.0: 0.237125, 4.0: 0.135625, 3.0: 0.068625, 2.0: 0.063375}\n","\n","1-gram predicted rating distribution:  {5.0: 0.4035, 1.0: 0.22425, 4.0: 0.2135, 3.0: 0.089125, 2.0: 0.069625}\n","\n","**# sample: 60000**\n","\n","1-gram accuracy:  0.6444166666666666\n","\n","(remove words appear less than 1200)\n","\n","1-gram actual rating distribution:  {5.0: 0.49475, 1.0: 0.23941666666666667, 4.0: 0.13425, 2.0: 0.06816666666666667, 3.0: 0.06341666666666666}\n","\n","1-gram predicted rating distribution:  {5.0: 0.40358333333333335, 1.0: 0.2325, 4.0: 0.21633333333333332, 3.0: 0.08091666666666666, 2.0: 0.06666666666666667}\n","\n","\n","**# sample: 60000**\n","\n","(remove words appear less than 1000)\n","\n","1-gram accuracy:  0.65325\n","\n","1-gram actual rating distribution:  {5.0: 0.48483333333333334, 1.0: 0.24166666666666667, 4.0: 0.13958333333333334, 2.0: 0.07025, 3.0: 0.06366666666666666}\n","\n","1-gram predicted rating distribution:  {5.0: 0.40066666666666667, 1.0: 0.23608333333333334, 4.0: 0.21825, 3.0: 0.08191666666666667, 2.0: 0.06308333333333334}"]},{"cell_type":"code","metadata":{"id":"_jEJeImNRK3o","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rZ0NFJsa6BNB","colab_type":"text"},"source":["#Moving 500 features\n","\n","**1-gram accuracy:  0.605 (# sample 10000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.4915, 1.0: 0.2445, 4.0: 0.134, 3.0: 0.0655, 2.0: 0.0645}\n","\n","1-gram predicted rating distribution:  {5.0: 0.363, 1.0: 0.2205, 4.0: 0.204, 3.0: 0.1435, 2.0: 0.069}\n","\n","\n","**1-gram accuracy:  0.612 (# sample 20000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.5015, 1.0: 0.2485, 4.0: 0.13, 2.0: 0.0605, 3.0: 0.0595}\n","\n","1-gram predicted rating distribution:  {5.0: 0.383, 1.0: 0.22, 4.0: 0.175, 3.0: 0.1375, 2.0: 0.0845}\n","<br>\n","\n","\n","**1-gram accuracy:  0.6348333333333334 (# sample 30000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.492, 1.0: 0.24, 4.0: 0.1335, 2.0: 0.0695, 3.0: 0.065}\n","\n","1-gram predicted rating distribution:  {5.0: 0.3983333333333333, 1.0: 0.23016666666666666, 4.0: 0.203, 3.0: 0.10383333333333333, 2.0: 0.06466666666666666}\n","<br>\n","\n","\n","**1-gram accuracy:  0.634875 (40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.488, 1.0: 0.24925, 4.0: 0.133375, 2.0: 0.06925, 3.0: 0.060125}\n","\n","1-gram predicted rating distribution:  {5.0: 0.388, 1.0: 0.237, 4.0: 0.21025, 3.0: 0.099625, 2.0: 0.065125}\n","\n","**1-gram accuracy:  0.647625(40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.492625, 1.0: 0.24575, 4.0: 0.1325, 3.0: 0.066125, 2.0: 0.063}\n","1-gram predicted rating\n","\n","distribution:  {5.0: 0.394125, 1.0: 0.2355, 4.0: 0.2135, 3.0: 0.083125, 2.0: 0.07375}\n","\n","\n","**1-gram accuracy:  0.655125 (40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.49675, 1.0: 0.2435, 4.0: 0.13325, 2.0: 0.067, 3.0: 0.0595}\n","\n","1-gram predicted rating distribution:  {5.0: 0.4055, 1.0: 0.232375, 4.0: 0.2115, 3.0: 0.08125, 2.0: 0.069375}\n","\n","**1-gram accuracy:  0.636375 (40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.491125, 1.0: 0.24375, 4.0: 0.13775, 2.0: 0.065, 3.0: 0.062375}\n","\n","1-gram predicted rating distribution:  {5.0: 0.3945, 1.0: 0.231, 4.0: 0.219375, 3.0: 0.085375, 2.0: 0.06975}"]},{"cell_type":"code","metadata":{"id":"Zff6fy4vOngo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aXcjI-06HRA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZgfKfy8ITwEs","colab_type":"text"},"source":["#Removing 1000\n","**1-gram accuracy:  0.64225(40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.4805, 1.0: 0.25025, 4.0: 0.1445, 3.0: 0.0635, 2.0: 0.06125}\n","\n","1-gram predicted rating distribution:  {5.0: 0.394, 1.0: 0.239125, 4.0: 0.213375, 3.0: 0.0815, 2.0: 0.072}\n","\n","**1-gram accuracy:  0.642(40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.491125, 1.0: 0.2465, 4.0: 0.138125, 2.0: 0.064625, 3.0: 0.059625}\n","\n","1-gram predicted rating distribution:  {5.0: 0.40175, 1.0: 0.231375, 4.0: 0.212125, 3.0: 0.085, 2.0: 0.06975}\n","\n","**1-gram accuracy:  0.646125(40000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.481875, 1.0: 0.2535, 4.0: 0.136, 2.0: 0.06475, 3.0: 0.063875}\n","\n","1-gram predicted rating distribution:  {5.0: 0.39, 1.0: 0.237625, 4.0: 0.215875, 3.0: 0.08375, 2.0: 0.07275}\n","\n","\n","**1-gram accuracy:  0.650625(80000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.4905, 1.0: 0.241875, 4.0: 0.133625, 2.0: 0.067125, 3.0: 0.066875}\n","\n","1-gram predicted rating distribution:  {5.0: 0.4003125, 1.0: 0.2340625, 4.0: 0.2199375, 3.0: 0.0798125, 2.0: 0.065875}"]},{"cell_type":"code","metadata":{"id":"tQqSc0oOT7ok","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L0Ucv_Vie7mP","colab_type":"text"},"source":["# **Removing 750**\n","**1-gram accuracy:  0.6511666666666667(60000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.489, 1.0: 0.24091666666666667, 4.0: 0.13775, 2.0: 0.06708333333333333, 3.0: 0.06525}\n","\n","1-gram predicted rating distribution:  {5.0: 0.4028333333333333, 1.0: 0.23758333333333334, 4.0: 0.21391666666666667, 3.0: 0.08775, 2.0: 0.057916666666666665}\n","\n","\n","**1-gram accuracy:  0.649 (60000)**\n","\n","1-gram actual rating distribution:  {5.0: 0.48741666666666666, 1.0: 0.24791666666666667, 4.0: 0.13025, 2.0: 0.07025, 3.0: 0.06416666666666666}\n","\n","1-gram predicted rating distribution:  {5.0: 0.399, 1.0: 0.242, 4.0: 0.21166666666666667, 3.0: 0.08291666666666667, 2.0: 0.06441666666666666}"]},{"cell_type":"code","metadata":{"id":"02hK7uSxfRcP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}